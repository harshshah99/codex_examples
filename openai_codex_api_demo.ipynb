{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic file I/O operations in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"davinci-codex\",\n",
    "  prompt=\"#python\\n#create a new file and add first 10 letters of the alphabet to it\\n\\n#code\\n\",\n",
    "  temperature=0.06,\n",
    "  max_tokens=317,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = open(\"file1.txt\", \"w\")\n",
      "for i in range(10):\n",
      "    f.write(chr(i+97))\n",
      "f.close()\n",
      "\n",
      "#read the file and print the contents\n",
      "f = open(\"file1.txt\", \"r\")\n",
      "print(f.read())\n",
      "f.close()\n"
     ]
    }
   ],
   "source": [
    "print(response.to_dict()['choices'][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Pytorch convertibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"davinci-codex\",\n",
    "  prompt=\"# Convert the following Keras code into Pytorch code\\n\\n### Keras Code\\nimport numpy as np\\nimport mnist\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.utils import to_categorical\\n\\ntrain_images = mnist.train_images()\\ntrain_labels = mnist.train_labels()\\ntest_images = mnist.test_images()\\ntest_labels = mnist.test_labels()\\n\\n# Normalize the images.\\ntrain_images = (train_images / 255) - 0.5\\ntest_images = (test_images / 255) - 0.5\\n\\n# Flatten the images.\\ntrain_images = train_images.reshape((-1, 784))\\ntest_images = test_images.reshape((-1, 784))\\n\\n# Build the model.\\nmodel = Sequential([\\n  Dense(64, activation='relu', input_shape=(784,)),\\n  Dense(64, activation='relu'),\\n  Dense(10, activation='softmax'),\\n])\\n\\n# Compile the model.\\nmodel.compile(\\n  optimizer='adam',\\n  loss='categorical_crossentropy',\\n  metrics=['accuracy'],\\n)\\n\\n# Train the model.\\nmodel.fit(\\n  train_images,\\n  to_categorical(train_labels),\\n  epochs=5,\\n  batch_size=32,\\n)\\n\\n### Pytorch Code\",\n",
    "  temperature=0.09,\n",
    "  max_tokens=1402,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Convert the following Keras code into Pytorch code\n",
      "\n",
      "### Keras Code\n",
      "import numpy as np\n",
      "import mnist\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.utils import to_categorical\n",
      "\n",
      "train_images = mnist.train_images()\n",
      "train_labels = mnist.train_labels()\n",
      "test_images = mnist.test_images()\n",
      "test_labels = mnist.test_labels()\n",
      "\n",
      "# Normalize the images.\n",
      "train_images = (train_images / 255) - 0.5\n",
      "test_images = (test_images / 255) - 0.5\n",
      "\n",
      "# Flatten the images.\n",
      "train_images = train_images.reshape((-1, 784))\n",
      "test_images = test_images.reshape((-1, 784))\n",
      "\n",
      "# Build the model.\n",
      "model = Sequential([\n",
      "  Dense(64, activation='relu', input_shape=(784,)),\n",
      "  Dense(64, activation='relu'),\n",
      "  Dense(10, activation='softmax'),\n",
      "])\n",
      "\n",
      "# Compile the model.\n",
      "model.compile(\n",
      "  optimizer='adam',\n",
      "  loss='categorical_crossentropy',\n",
      "  metrics=['accuracy'],\n",
      ")\n",
      "\n",
      "# Train the model.\n",
      "model.fit(\n",
      "  train_images,\n",
      "  to_categorical(train_labels),\n",
      "  epochs=5,\n",
      "  batch_size=32,\n",
      ")\n",
      "\n",
      "### Pytorch Code\n"
     ]
    }
   ],
   "source": [
    "#Keras Code\n",
    "prompt=\"# Convert the following Keras code into Pytorch code\\n\\n### Keras Code\\nimport numpy as np\\nimport mnist\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.utils import to_categorical\\n\\ntrain_images = mnist.train_images()\\ntrain_labels = mnist.train_labels()\\ntest_images = mnist.test_images()\\ntest_labels = mnist.test_labels()\\n\\n# Normalize the images.\\ntrain_images = (train_images / 255) - 0.5\\ntest_images = (test_images / 255) - 0.5\\n\\n# Flatten the images.\\ntrain_images = train_images.reshape((-1, 784))\\ntest_images = test_images.reshape((-1, 784))\\n\\n# Build the model.\\nmodel = Sequential([\\n  Dense(64, activation='relu', input_shape=(784,)),\\n  Dense(64, activation='relu'),\\n  Dense(10, activation='softmax'),\\n])\\n\\n# Compile the model.\\nmodel.compile(\\n  optimizer='adam',\\n  loss='categorical_crossentropy',\\n  metrics=['accuracy'],\\n)\\n\\n# Train the model.\\nmodel.fit(\\n  train_images,\\n  to_categorical(train_labels),\\n  epochs=5,\\n  batch_size=32,\\n)\\n\\n### Pytorch Code\",\n",
    "print(prompt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "from torchvision import datasets, transforms\n",
      "\n",
      "# Load the data.\n",
      "train_loader = torch.utils.data.DataLoader(\n",
      "  datasets.MNIST('../data', train=True, download=True,\n",
      "                 transform=transforms.Compose([\n",
      "                   transforms.ToTensor(),\n",
      "                   transforms.Normalize((0.1307,), (0.3081,))\n",
      "                 ])),\n",
      "  batch_size=32, shuffle=True)\n",
      "test_loader = torch.utils.data.DataLoader(\n",
      "  datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
      "                   transforms.ToTensor(),\n",
      "                   transforms.Normalize((0.1307,), (0.3081,))\n",
      "                 ])),\n",
      "  batch_size=32, shuffle=True)\n",
      "\n",
      "# Build the model.\n",
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.fc1 = nn.Linear(784, 64)\n",
      "        self.fc2 = nn.Linear(64, 64)\n",
      "        self.fc3 = nn.Linear(64, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = x.view(-1, 784)\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = F.relu(self.fc2(x))\n",
      "        x = self.fc3(x)\n",
      "        return F.log_softmax(x, dim=1)\n",
      "\n",
      "model = Net()\n",
      "\n",
      "# Train the model.\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
      "\n",
      "def train(epoch):\n",
      "    model.train()\n",
      "    for batch_idx, (data, target) in enumerate(train_loader):\n",
      "        optimizer.zero_grad()\n",
      "        output = model(data)\n",
      "        loss = criterion(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        if batch_idx % 10 == 0:\n",
      "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
      "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
      "                100. * batch_idx / len(train_loader), loss.item()))\n",
      "\n",
      "def test():\n",
      "    model.eval()\n",
      "    test_loss = 0\n",
      "    correct = 0\n",
      "    for data, target in test_loader:\n",
      "        output = model(data)\n",
      "        # sum up batch loss\n",
      "        test_loss += criterion(output, target).item()\n",
      "        # get the index of the max\n",
      "        pred = output.data.max(1, keepdim=True)[1]\n",
      "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
      "\n",
      "    test_loss /= len(test_loader.dataset)\n",
      "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
      "        test_loss, correct, len(test_loader.dataset),\n",
      "        100. * correct / len(test_loader.dataset)))\n",
      "\n",
      "for epoch in range(1, 10):\n",
      "    train(epoch)\n",
      "    test()\n",
      "\n",
      "# Save the model\n",
      "torch.save(model.state_dict(), 'mnist_model.pth')\n",
      "\n",
      "# Load the model\n",
      "model.load_state_dict(torch.load('mnist_model.pth'))\n",
      "\n",
      "# Convert the model to the ONNX format\n",
      "torch_out = torch.onnx._export(model,             # model being run\n",
      "                               (data),            # model input (or a tuple for multiple inputs)\n",
      "                               \"mnist.onnx\",       # where to save the model (can be a file or file-like object)\n",
      "                               export_params=True)      # store the trained parameter weights inside the model file\n",
      "\n",
      "# Load the ONNX model\n",
      "model = onnx.load(\"mnist.onnx\")\n",
      "\n",
      "# Import the ONNX model to the ONNX runtime\n",
      "ort_session = onnxruntime.InferenceSession(\"mnist.onnx\")\n",
      "\n",
      "# Get the name of the first input of the model\n",
      "input_name = ort_session.get_inputs()[0].name\n",
      "\n",
      "# Run the ONNX model with the ONNX runtime\n",
      "ort_inputs = {input_name: data.numpy()}\n",
      "ort_outs = ort_session.run(None, ort_inputs)\n",
      "\n",
      "# Verify the numerical correctness upto 3 decimal places\n",
      "np.testing.assert_almost_equal(torch_out[0], ort_outs[0], decimal=3)\n",
      "\n",
      "print(\"Exported model has been executed on ONNX runtime with Python and the result is verified numerically.\")\n"
     ]
    }
   ],
   "source": [
    "print(response.to_dict()['choices'][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10,(7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-02d0da4de5e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "a[0][1] = np.nan\n",
    "a[3][2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"davinci-codex\",\n",
    "  prompt=\"# Explain how to solve the following error \\n \\n### Code with Error\\na = np.random.randint(0,10,(7,5))\\na[0][1] = np.nan\\n\\n### Error Message\\nValueError: cannot convert float NaN to integer\\n\\n### Fixed Code\",\n",
    "  temperature=0.09,\n",
    "  max_tokens=272,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a = np.random.randint(0,10,(7,5))\n",
      "a[0][1] = np.nan\n",
      "a = a.astype(float)\n",
      "a[0][1] = np.nan\n",
      "\n",
      "# Explain how to solve the following error \n",
      "\n",
      "### Code with Error\n",
      "a = np.random.randint(0,10,(7,5))\n",
      "a[0][1] = np.nan\n",
      "\n",
      "### Error Message\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "### Fixed Code\n",
      "a = np.random.randint(0,10,(7,5))\n",
      "a[0][1] = np.nan\n",
      "a = a.astype(float)\n",
      "a[0][1] = np.nan\n",
      "\n",
      "# Explain how to solve the following error \n",
      "\n",
      "### Code with Error\n",
      "a = np.random.randint(0,10,(7,5))\n",
      "a[0][1] = np.nan\n",
      "\n",
      "### Error Message\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "### Fixed Code\n",
      "a = np.random.randint(0,10,(7,5))\n",
      "a[0][1] = np.nan\n",
      "a =\n"
     ]
    }
   ],
   "source": [
    "print(response.to_dict()['choices'][0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
